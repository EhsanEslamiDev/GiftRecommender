{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f01a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts.chat import (\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate, format_document\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99dc27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGUAGE_MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12806a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template: str = \"\"\"/\n",
    "    imagine that you are a clerk at a supermarket store. Consider the following description for a product that the customer is looking for: /\n",
    "      {description} /\n",
    "    use the below retrived products information and choose the most relavent one for the needs of the customer: /\n",
    "      {context} /\n",
    "      give as response, the information on the product most relavent to the need of the customer. You should strictly use one of the products above. /\n",
    "      In your response include all the relavent information on the product.\n",
    "    \"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    input_variables=[\"description\", \"context\"],\n",
    "    template=\"{description}\",\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "\n",
    "\n",
    "# Create a template including your metadata\n",
    "doc_template = PromptTemplate.from_template(\"\"\"\n",
    "Product: {product}\n",
    "Category: {category} → {sub_category}\n",
    "Brand: {brand}\n",
    "Sale Price: ₹{sale_price}, Market Price: ₹{market_price}\n",
    "Type: {type}, Rating: {rating}\n",
    "Description:\n",
    "{page_content}\n",
    "\"\"\".strip())\n",
    "\n",
    "\n",
    "def get_retriever(query: str):\n",
    "    qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "    qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "    collection_name = \"product_catalog\"\n",
    "\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "    vectorstore = QdrantVectorStore.from_existing_collection(\n",
    "        collection_name=collection_name,\n",
    "        embedding=embedding_model,          \n",
    "        url=qdrant_url,\n",
    "        api_key=qdrant_api_key,\n",
    "        prefer_grpc=False,\n",
    "        timeout=60,\n",
    "    )\n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n---\\n\".join(format_document(doc, doc_template) for doc in docs)\n",
    "\n",
    "\n",
    "def generate_response(retriever, query: str) -> str:\n",
    "    # Step 1: Retrieve documents (with metadata)\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    # Step 2: Format documents for the prompt\n",
    "    context = format_docs(docs)\n",
    "\n",
    "    # Step 3: Create the full chain (prompt → model → parser)\n",
    "    chain = (\n",
    "        {\"context\": RunnablePassthrough(), \"description\": RunnablePassthrough()}\n",
    "        | chat_prompt_template  # assumes you've already defined this\n",
    "        | model                 # assumes you've defined your ChatOpenAI model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # Step 4: Invoke the chain\n",
    "    return chain.invoke({\"description\": query, \"context\": context})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Based on your request to cook a Persian food for three people within a budget of max 300 rubles, the most relevant product from the information provided would be the **\"Hara Bhara Veg Kebab\"** by **Safal**. Here are the details of the product:\n",
      "\n",
      "- **Category:** Snacks & Branded Foods → Frozen Veggies & Snacks\n",
      "- **Brand:** Safal\n",
      "- **Sale Price:** ₹70.0\n",
      "- **Market Price:** ₹70.0\n",
      "- **Type:** Frozen Veg Snacks\n",
      "- **Rating:** 3.9\n",
      "- **Description:** The Goodness of green loaded with taste! It is rich in green peas, containing 50% peas, spinach, spices, and condiments. A flavorful, traditional recipe ready in 3 minutes. Enjoy the delicious kebab with family & friends.\n",
      "\n",
      "This product fits within your budget and can be a tasty addition to your Persian meal for three people.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"I want to cook a persian food for tree person and with max 300 rubles price.\"\n",
    "retriever = get_retriever(user_query)\n",
    "\n",
    "response = generate_response(retriever, user_query)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb4e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
